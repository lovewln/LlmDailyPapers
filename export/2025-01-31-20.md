# large language model
## Foundational Models for 3D Point Clouds: A Survey and Outlook
- **Url**: http://arxiv.org/abs/2501.18594v1
- **Authors**: ['Vishal Thengane', 'Xiatian Zhu', 'Salim Bouzerdoum', 'Son Lam Phung', 'Yunpeng Li']
- **Abstrat**: The 3D point cloud representation plays a crucial role in preserving the geometric fidelity of the physical world, enabling more accurate complex 3D environments. While humans naturally comprehend the intricate relationships between objects and variations through a multisensory system, artificial intelligence (AI) systems have yet to fully replicate this capacity. To bridge this gap, it becomes essential to incorporate multiple modalities. Models that can seamlessly integrate and reason across these modalities are known as foundation models (FMs). The development of FMs for 2D modalities, such as images and text, has seen significant progress, driven by the abundant availability of large-scale datasets. However, the 3D domain has lagged due to the scarcity of labelled data and high computational overheads. In response, recent research has begun to explore the potential of applying FMs to 3D tasks, overcoming these challenges by leveraging existing 2D knowledge. Additionally, language, with its capacity for abstract reasoning and description of the environment, offers a promising avenue for enhancing 3D understanding through large pre-trained language models (LLMs). Despite the rapid development and adoption of FMs for 3D vision tasks in recent years, there remains a gap in comprehensive and in-depth literature reviews. This article aims to address this gap by presenting a comprehensive overview of the state-of-the-art methods that utilize FMs for 3D visual understanding. We start by reviewing various strategies employed in the building of various 3D FMs. Then we categorize and summarize use of different FMs for tasks such as perception tasks. Finally, the article offers insights into future directions for research and development in this field. To help reader, we have curated list of relevant papers on the topic: https://github.com/vgthengane/Awesome-FMs-in-3D.





## Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs
- **Url**: http://arxiv.org/abs/2501.18585v1
- **Authors**: ['Yue Wang', 'Qiuzhi Liu', 'Jiahao Xu', 'Tian Liang', 'Xingyu Chen', 'Zhiwei He', 'Linfeng Song', 'Dian Yu', 'Juntao Li', 'Zhuosheng Zhang', 'Rui Wang', 'Zhaopeng Tu', 'Haitao Mi', 'Dong Yu']
- **Abstrat**: Large language models (LLMs) such as OpenAI's o1 have demonstrated remarkable abilities in complex reasoning tasks by scaling test-time compute and exhibiting human-like deep thinking. However, we identify a phenomenon we term underthinking, where o1-like LLMs frequently switch between different reasoning thoughts without sufficiently exploring promising paths to reach a correct solution. This behavior leads to inadequate depth of reasoning and decreased performance, particularly on challenging mathematical problems. To systematically analyze this issue, we conduct experiments on three challenging test sets and two representative open-source o1-like models, revealing that frequent thought switching correlates with incorrect responses. We introduce a novel metric to quantify underthinking by measuring token efficiency in incorrect answers. To address underthinking, we propose a decoding strategy with thought switching penalty TIP that discourages premature transitions between thoughts, encouraging deeper exploration of each reasoning path. Experimental results demonstrate that our approach improves accuracy across challenging datasets without requiring model fine-tuning. Our findings contribute to understanding reasoning inefficiencies in o1-like LLMs and offer a practical solution to enhance their problem-solving capabilities.





## Token-Hungry, Yet Precise: DeepSeek R1 Highlights the Need for Multi-Step Reasoning Over Speed in MATH
- **Url**: http://arxiv.org/abs/2501.18576v1
- **Authors**: ['Evgenii Evstafev']
- **Abstrat**: This study investigates the performance of the DeepSeek R1 language model on 30 challenging mathematical problems derived from the MATH dataset, problems that previously proved unsolvable by other models under time constraints. Unlike prior work, this research removes time limitations to explore whether DeepSeek R1's architecture, known for its reliance on token-based reasoning, can achieve accurate solutions through a multi-step process. The study compares DeepSeek R1 with four other models (gemini-1.5-flash-8b, gpt-4o-mini-2024-07-18, llama3.1:8b, and mistral-8b-latest) across 11 temperature settings. Results demonstrate that DeepSeek R1 achieves superior accuracy on these complex problems but generates significantly more tokens than other models, confirming its token-intensive approach. The findings highlight a trade-off between accuracy and efficiency in mathematical problem-solving with large language models: while DeepSeek R1 excels in accuracy, its reliance on extensive token generation may not be optimal for applications requiring rapid responses. The study underscores the importance of considering task-specific requirements when selecting an LLM and emphasizes the role of temperature settings in optimizing performance.





## BounTCHA: A CAPTCHA Utilizing Boundary Identification in AI-extended Videos
- **Url**: http://arxiv.org/abs/2501.18565v1
- **Authors**: ['Lehao Lin', 'Ke Wang', 'Maha Abdallah', 'Wei Cai']
- **Abstrat**: In recent years, the rapid development of artificial intelligence (AI) especially multi-modal Large Language Models (MLLMs), has enabled it to understand text, images, videos, and other multimedia data, allowing AI systems to execute various tasks based on human-provided prompts. However, AI-powered bots have increasingly been able to bypass most existing CAPTCHA systems, posing significant security threats to web applications. This makes the design of new CAPTCHA mechanisms an urgent priority. We observe that humans are highly sensitive to shifts and abrupt changes in videos, while current AI systems still struggle to comprehend and respond to such situations effectively. Based on this observation, we design and implement BounTCHA, a CAPTCHA mechanism that leverages human perception of boundaries in video transitions and disruptions. By utilizing AI's capability to expand original videos with prompts, we introduce unexpected twists and changes to create a pipeline for generating short videos for CAPTCHA purposes. We develop a prototype and conduct experiments to collect data on humans' time biases in boundary identification. This data serves as a basis for distinguishing between human users and bots. Additionally, we perform a detailed security analysis of BounTCHA, demonstrating its resilience against various types of attacks. We hope that BounTCHA will act as a robust defense, safeguarding millions of web applications in the AI-driven era.





## Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics
- **Url**: http://arxiv.org/abs/2501.14883v2
- **Authors**: ['Ameya Godbole', 'Robin Jia']
- **Abstrat**: Improvements in large language models have led to increasing optimism that they can serve as reliable evaluators of natural language generation outputs. In this paper, we challenge this optimism by thoroughly re-evaluating five state-of-the-art factuality metrics on a collection of 11 datasets for summarization, retrieval-augmented generation, and question answering. We find that these evaluators are inconsistent with each other and often misestimate system-level performance, both of which can lead to a variety of pitfalls. We further show that these metrics exhibit biases against highly paraphrased outputs and outputs that draw upon faraway parts of the source documents. We urge users of these factuality metrics to proceed with caution and manually validate the reliability of these metrics in their domain of interest before proceeding.





## Semantic Web and Creative AI -- A Technical Report from ISWS 2023
- **Url**: http://arxiv.org/abs/2501.18542v1
- **Authors**: ['Raia Abu Ahmad', 'Reham Alharbi', 'Roberto Barile', 'Martin Böckling', 'Francisco Bolanos', 'Sara Bonfitto', 'Oleksandra Bruns', 'Irene Celino', 'Yashrajsinh Chudasama', 'Martin Critelli', "Claudia d'Amato", "Giada D'Ippolito", 'Ioannis Dasoulas', 'Stefano De Giorgis', 'Vincenzo De Leo', 'Chiara Di Bonaventura', 'Marco Di Panfilo', 'Daniil Dobriy', 'John Domingue', 'Xuemin Duan', 'Michel Dumontier', 'Sefika Efeoglu', 'Ruben Eschauzier', 'Fakih Ginwa', 'Nicolas Ferranti', 'Arianna Graciotti', 'Philipp Hanisch', 'George Hannah', 'Golsa Heidari', 'Aidan Hogan', 'Hassan Hussein', 'Alexane Jouglar', 'Jan-Christoph Kalo', 'Manoé Kieffer', 'Antonis Klironomos', 'Inês Koch', 'Weronika Lajewska', 'Nicolas Lazzari', 'Mikael Lindekrans', 'Anna Sofia Lippolis', 'Majlinda Llugiqi', 'Eleonora Mancini', 'Eleonora Marzi', 'Laura Menotti', 'Daniela Milon Flores', 'Soulakshmee Nagowah', 'Kerstin Neubert', 'Emetis Niazmand', 'Ebrahim Norouzi', 'Beatriz Olarte Martinez', 'Anouk Michelle Oudshoorn', 'Andrea Poltronieri', 'Valentina Presutti', 'Disha Purohit', 'Ensiyeh Raoufi', 'Celian Ringwald', 'Johanna Rockstroh', 'Sebastian Rudolph', 'Harald Sack', 'Zafar Saeed', 'Mohammad Javad Saeedizade', 'Aya Sahbi', 'Cristian Santini', 'Aleksandra Simic', 'Dennis Sommer', 'Rita Sousa', 'Mary Ann Tan', 'Vidyashree Tarikere', 'Tabea Tietz', 'Liam Tirpitz', 'Arnaldo Tomasino', 'Frank van Harmelen', 'Joao Vissoci', 'Caitlin Woods', 'Bohui Zhang', 'Xinyue Zhang', 'Heng Zheng']
- **Abstrat**: The International Semantic Web Research School (ISWS) is a week-long intensive program designed to immerse participants in the field. This document reports a collaborative effort performed by ten teams of students, each guided by a senior researcher as their mentor, attending ISWS 2023. Each team provided a different perspective to the topic of creative AI, substantiated by a set of research questions as the main subject of their investigation. The 2023 edition of ISWS focuses on the intersection of Semantic Web technologies and Creative AI. ISWS 2023 explored various intersections between Semantic Web technologies and creative AI. A key area of focus was the potential of LLMs as support tools for knowledge engineering. Participants also delved into the multifaceted applications of LLMs, including legal aspects of creative content production, humans in the loop, decentralised approaches to multimodal generative AI models, nanopublications and AI for personal scientific knowledge graphs, commonsense knowledge in automatic story and narrative completion, generative AI for art critique, prompt engineering, automatic music composition, commonsense prototyping and conceptual blending, and elicitation of tacit knowledge. As Large Language Models and semantic technologies continue to evolve, new exciting prospects are emerging: a future where the boundaries between creative expression and factual knowledge become increasingly permeable and porous, leading to a world of knowledge that is both informative and inspiring.





## Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models
- **Url**: http://arxiv.org/abs/2501.17595v2
- **Authors**: ['Behraj Khan', 'Tahir Syed']
- **Abstrat**: Confidence calibration is an emerging challenge in real-world decision systems based on foundations models when used for downstream vision classification tasks. Due to various reasons exposed, logit scores on the CLIP head remain large irrespective of whether the image-language pairs reconcile. It is difficult to address in data space, given the few-shot regime. We propose a penalty incorporated into loss objective that penalizes incorrect classifications whenever one is made during finetuning, by moving an amount of log-likelihood to the true class commensurate to the relative amplitudes of the two likelihoods. We refer to it as \textit{confidence misalignment penalty (CMP)}. Extensive experiments on $12$ vision datasets and $5$ domain generalization datasets supports the calibration performance of our method against stat-of-the-art. CMP outperforms the benchmarked prompt learning methods, demonstrating average improvement in Expected Calibration Error (ECE) by average $6.01$\%, $4.01$ \% at minimum and $9.72$\% at maximum.




